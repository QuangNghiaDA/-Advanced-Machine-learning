{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trần Quang Nghĩa - 19110392\n",
    "\n",
    "Lab 1 - MHNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import các thư viện \n",
    "import tensorflow as tf #thư viện tensorflow\n",
    "import keras #Thư viện keras\n",
    "import numpy as np #Thư viện numpy\n",
    "import matplotlib.pyplot as plt #Thư viện matplotlib để vẽ đồ thị"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kiểm tra version của keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "Có 60000 ảnh dùng để train và valid, 10000 ảnh dùng để test\n",
      "Mỗi ảnh có một kênh màu, kích thước 28x28\n",
      "\n",
      "Ảnh đầu tiên của tập train\n",
      "Label đầu tiên của tập train:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tải dataset MNIST từ tensorflow\n",
    "## MNIST là bài toán dự đoán một ảnh thể hiện ký tự số nào (dùng ảnh trắng đen)\n",
    "## tải MNIST dataset từ keras\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "##resacle ảnh thành ảnh thực trong đoạn [0,1]\n",
    "X_train, X_test = X_train/255.0, X_test/255.0\n",
    "\n",
    "##in dataset\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(\"Có 60000 ảnh dùng để train và valid, 10000 ảnh dùng để test\")\n",
    "print(\"Mỗi ảnh có một kênh màu, kích thước 28x28\")\n",
    "print()\n",
    "\n",
    "## in thử ảnh một ảnh\n",
    "print(\"Ảnh đầu tiên của tập train\")\n",
    "print(\"Label đầu tiên của tập train: \", y_train[0])\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#Tách một phần tập train thành tập valid\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1) # Tách theo tỉ lệ validation/train=1/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4l2OF0w6VU0c",
    "outputId": "3b8ba391-306e-470e-8bad-5365e7f35935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước input: (None, 28, 28), None tượng trưng cho số lượng ảnh một batch không xác định trước\n",
      "Kích thước sau reshape: (None, 28, 28, 1)\n",
      "Kích thước flatten: (None, 784)\n",
      "Kích thước fc1: (None, 200)\n",
      "Kích thước fc1: (None, 100)\n",
      "Kích thước fc1: (None, 50)\n",
      "Kích thước fc1: (None, 20)\n",
      "Cấu trúc của model: \n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,380\n",
      "Trainable params: 183,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Tạo layer input, mỗi data point có kích thước (28,28)\n",
    "inputs = keras.layers.Input(shape=(28,28))\n",
    "print(\"Kích thước input: {}, None tượng trưng cho số lượng ảnh một batch không xác định trước\".format(inputs.shape))\n",
    "\n",
    "## Reshape input\n",
    "## do input vào lớp convolutional layer cần có 4 chiều, chiều cuối là số kênh,\n",
    "## ảnh mnist là ảnh xám nên chỉ có một kênh\n",
    "inputs_reshape = keras.layers.Reshape((28,28,1))(inputs)\n",
    "print(\"Kích thước sau reshape: {}\".format(inputs_reshape.shape))\n",
    "\n",
    "\n",
    "\n",
    "## Flatten lớp conv trước khi cho vào lớp dense, vì lớp dense yêu cầu input chỉ là vector\n",
    "flatten = keras.layers.Flatten()(inputs)\n",
    "print(\"Kích thước flatten: {}\".format(flatten.shape))\n",
    "\n",
    "dense1= keras.layers.Dense(units=200,activation=\"relu\")(flatten)\n",
    "print(\"Kích thước fc1: {}\".format(dense1.shape))\n",
    "\n",
    "dense2= keras.layers.Dense(units=100,activation=\"relu\")(dense1)\n",
    "print(\"Kích thước fc1: {}\".format(dense2.shape))\n",
    "\n",
    "dense3= keras.layers.Dense(units=50,activation=\"relu\")(dense2)\n",
    "print(\"Kích thước fc1: {}\".format(dense3.shape))\n",
    "\n",
    "dense4= keras.layers.Dense(units=20,activation=\"relu\")(dense3)\n",
    "print(\"Kích thước fc1: {}\".format(dense4.shape))\n",
    "\n",
    "## Lớp Fully conntected với hàm kích hoạt softmax. units là số Node\n",
    "    ### Lưu ý vì đây là lớp để classify nên hàm kích hoạt bắt buộc phải là softmax, \n",
    "softmax = keras.layers.Dense(units=10, activation='softmax')(dense4)\n",
    "\n",
    "\n",
    "## Tạo model, với input là lớp inputs, outputs là lớp softmax\n",
    "model = keras.models.Model(inputs=inputs, outputs=softmax)\n",
    "\n",
    "## Compile model, \n",
    "    ### optimizer là thuật toán tối ưu ở đây dùng adam\n",
    "    ### loss function là hàm mất mát ở đây dùng sparse_categorical_crossentropy\n",
    "    ### metrics: để theo dõi các đánh giá trong quá trình huấn luyện. Đối với tập MNIST chúng ta dùng accuracy trên top1\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "             metrics=[\"accuracy\"])\n",
    "    \n",
    "\n",
    "## In toàn bộ cấu trúc của model\n",
    "print(\"Cấu trúc của model: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aA5v3bVbFefX",
    "outputId": "85113745-4b1b-4474-e054-d2062ac6a4df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "540/540 [==============================] - 3s 4ms/step - loss: 0.3412 - accuracy: 0.8968 - val_loss: 0.1563 - val_accuracy: 0.9513\n",
      "Epoch 2/10\n",
      "540/540 [==============================] - 2s 3ms/step - loss: 0.1248 - accuracy: 0.9620 - val_loss: 0.1294 - val_accuracy: 0.9627\n",
      "Epoch 3/10\n",
      "540/540 [==============================] - 2s 5ms/step - loss: 0.0843 - accuracy: 0.9740 - val_loss: 0.0970 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "540/540 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.9799 - val_loss: 0.0917 - val_accuracy: 0.9752\n",
      "Epoch 5/10\n",
      "540/540 [==============================] - 2s 3ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0814 - val_accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "540/540 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9883 - val_loss: 0.0844 - val_accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "540/540 [==============================] - 3s 6ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 0.0775 - val_accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "540/540 [==============================] - 3s 5ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.0853 - val_accuracy: 0.9752\n",
      "Epoch 9/10\n",
      "540/540 [==============================] - 2s 4ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.0807 - val_accuracy: 0.9765\n",
      "Epoch 10/10\n",
      "540/540 [==============================] - 3s 5ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0778 - val_accuracy: 0.9790\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9766\n",
      "Loss trên tập test:  0.09152644872665405  Accuracy trên tập test:  0.9765999913215637\n"
     ]
    }
   ],
   "source": [
    "# Dùng hàm fit để bắt đầu train\n",
    "## 2 tham số đầu là 2 numpy array, X_train là ảnh, y_train là label\n",
    "## batch_size: kích thước của data batch\n",
    "## epochs: số epoch tối đa muốn chạy\n",
    "## validation data: model sẽ được đánh giá trên tập valid mỗi epoch\n",
    "history=model.fit(X_train,y_train,\n",
    "                  epochs=10,\n",
    "                  batch_size=100,\n",
    "                  validation_data=(X_valid,y_valid))\n",
    "\n",
    "## Lưu model thành một file\n",
    "model.save_weights(\"first_model.h5\")\n",
    "\n",
    "\n",
    "## Load model\n",
    "model.load_weights(\"first_model.h5\")\n",
    "\n",
    "## Đánh giá model trên tập test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Loss trên tập test: \", test_loss,\" Accuracy trên tập test: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E_liXsGdscB"
   },
   "source": [
    "Cách tính params ở trên\n",
    "- param_number = output * (input + 1)\n",
    "$$ 157000 = 200 * (784 + 1)$$\n",
    "\n",
    "$$20100 = 100 * (200 + 1)$$\n",
    "\n",
    "$$5050 = 50 * (100 + 1)$$\n",
    "\n",
    "$$1020 = 20 * (50 + 1)$$\n",
    "\n",
    "$$210 = 10 * (20 + 1)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8brXUF17hhQP"
   },
   "source": [
    "Cấu trúc câu 1 có thể áp dụng cho bài toán Regression bằng cách đổi lớp đầu tiên thành `normalizer` và không cần sofmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước input: (None, 28, 28), None tượng trưng cho số lượng ảnh một batch không xác định trước\n",
      "Kích thước sau reshape: (None, 28, 28, 1)\n",
      "Kích thước conv: (None, 28, 28, 20), chiều cuối cùng chính là số filter\n",
      "Kích thước sau maxpool: (None, 14, 14, 20)\n",
      "Kích thước flatten: (None, 3920)\n",
      "Cấu trúc của model: \n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 14, 14, 20)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 3920)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                39210     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,730\n",
      "Trainable params: 39,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Tạo layer input, mỗi data point có kích thước (28,28)\n",
    "inputs = keras.layers.Input(shape=(28,28))\n",
    "print(\"Kích thước input: {}, None tượng trưng cho số lượng ảnh một batch không xác định trước\".format(inputs.shape))\n",
    "\n",
    "## Reshape input\n",
    "## do input vào lớp convolutional layer cần có 4 chiều, chiều cuối là số kênh,\n",
    "## ảnh mnist là ảnh xám nên chỉ có một kênh\n",
    "inputs_reshape = keras.layers.Reshape((28,28,1))(inputs)\n",
    "print(\"Kích thước sau reshape: {}\".format(inputs_reshape.shape))\n",
    "\n",
    "## Tạo Convolutional Layer\n",
    "### fileters: số lượng filter\n",
    "### kernel_size: kích thước của filter\n",
    "### strides: bước dịch của filter khi tính convolution\n",
    "### padding: thêm số 0 hoặc không tính khi tính filter ở biên\n",
    "    #### có 2 options: \"same\" là sẽ giữ nguyên kích thước ảnh sau khi qua lớp Convolution, \"valid\" kích thước ảnh sẽ đc tính đúng như công thức\n",
    "### activation: hàm kích hoạt của lớp convolution\n",
    "conv = keras.layers.Convolution2D(filters=20,\n",
    "                                 kernel_size=[5,5],\n",
    "                                 strides=[1,1],\n",
    "                                 padding='same',\n",
    "                                 activation=tf.nn.relu)(inputs_reshape)\n",
    "print(\"Kích thước conv: {}, chiều cuối cùng chính là số filter\".format(conv.shape))\n",
    "\n",
    "## Maxpooling\n",
    "### pool_size: kích thước pool để lấy max\n",
    "### strides: bước dịch của pool \n",
    "maxpool = keras.layers.MaxPool2D(pool_size=[2,2],\n",
    "                                strides=[2,2])(conv)\n",
    "print(\"Kích thước sau maxpool: {}\".format(maxpool.shape))\n",
    "\n",
    "## Flatten lớp conv trước khi cho vào lớp dense, vì lớp dense yêu cầu input chỉ là vector\n",
    "flatten = keras.layers.Flatten()(maxpool)\n",
    "print(\"Kích thước flatten: {}\".format(flatten.shape))\n",
    "\n",
    "## Lớp Fully conntected với hàm kích hoạt softmax. units là số Node\n",
    "    ### Lưu ý vì đây là lớp để classify nên hàm kích hoạt bắt buộc phải là softmax, \n",
    "softmax = keras.layers.Dense(units=10, activation='softmax')(flatten)\n",
    "\n",
    "\n",
    "## Tạo model, với input là lớp inputs, outputs là lớp softmax\n",
    "model = keras.models.Model(inputs=inputs, outputs=softmax)\n",
    "\n",
    "## Compile model, \n",
    "    ### optimizer là thuật toán tối ưu ở đây dùng adam\n",
    "    ### loss function là hàm mất mát ở đây dùng sparse_categorical_crossentropy\n",
    "    ### metrics: để theo dõi các đánh giá trong quá trình huấn luyện. Đối với tập MNIST chúng ta dùng accuracy trên top1\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "             metrics=[\"accuracy\"])\n",
    "    \n",
    "\n",
    "## In toàn bộ cấu trúc của model\n",
    "print(\"Cấu trúc của model: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước input: (None, 28, 28), None tượng trưng cho số lượng ảnh một batch không xác định trước\n",
      "Cấu trúc của model: \n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 20)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 10, 10, 20)        10020     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 20)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20)                10020     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,880\n",
      "Trainable params: 20,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Tạo layer input, mỗi data point có kích thước (28,28)\n",
    "inputs = keras.layers.Input(shape=(28,28))\n",
    "print(\"Kích thước input: {}, None tượng trưng cho số lượng ảnh một batch không xác định trước\".format(inputs.shape))\n",
    "\n",
    "## Reshape input\n",
    "## do input vào lớp convolutional layer cần có 4 chiều, chiều cuối là số kênh,\n",
    "## ảnh mnist là ảnh xám nên chỉ có một kênh\n",
    "inputs_reshape = keras.layers.Reshape((28,28,1))(inputs)\n",
    "\n",
    "\n",
    "## Tạo Convolutional Layer\n",
    "### fileters: số lượng filter\n",
    "### kernel_size: kích thước của filter\n",
    "### strides: bước dịch của filter khi tính convolution\n",
    "### padding: thêm số 0 hoặc không tính khi tính filter ở biên\n",
    "#### có 2 options: \"same\" là sẽ giữ nguyên kích thước ảnh sau khi qua lớp Convolution, \"valid\" kích thước ảnh sẽ đc tính đúng như công thức\n",
    "### activation: hàm kích hoạt của lớp convolution\n",
    "conv = keras.layers.Convolution2D(filters=20,\n",
    "                                 kernel_size=[5,5],\n",
    "                                 strides=[1,1],\n",
    "                                 padding='same',\n",
    "                                 activation=tf.nn.relu)(inputs_reshape)\n",
    "\n",
    "## Maxpooling\n",
    "### pool_size: kích thước pool để lấy max\n",
    "### strides: bước dịch của pool \n",
    "maxpool = keras.layers.MaxPool2D(pool_size=[2,2],\n",
    "                                strides=[2,2])(conv)\n",
    "\n",
    "conv1 = keras.layers.Convolution2D(filters=20,\n",
    "                                 kernel_size=[5,5],\n",
    "                                 strides=[1,1],\n",
    "                                 padding='valid',\n",
    "                                 activation=tf.nn.relu)(maxpool)\n",
    "maxpool1 = keras.layers.MaxPool2D(pool_size=[2,2],\n",
    "                                strides=[2,2])(conv1)\n",
    "\n",
    "## Flatten lớp conv trước khi cho vào lớp dense, vì lớp dense yêu cầu input chỉ là vector                           \n",
    "flatten = keras.layers.Flatten()(maxpool1)\n",
    "\n",
    "## Lớp Fully conntected với hàm kích hoạt softmax. units là số Node\n",
    "### Lưu ý vì đây là lớp để classify nên hàm kích hoạt bắt buộc phải là softmax, \n",
    "dense1= keras.layers.Dense(units=20,activation=\"relu\")(flatten)\n",
    "dense2= keras.layers.Dense(units=10,activation=\"relu\")(dense1)\n",
    "softmax = keras.layers.Dense(units=10, activation='softmax')(dense2)\n",
    "\n",
    "## Tạo model, với input là lớp inputs, outputs là lớp softmax\n",
    "model = keras.models.Model(inputs=inputs, outputs=softmax)\n",
    "\n",
    "## Compile model, \n",
    "    ### optimizer là thuật toán tối ưu ở đây dùng adam\n",
    "    ### loss function là hàm mất mát ở đây dùng sparse_categorical_crossentropy\n",
    "    ### metrics: để theo dõi các đánh giá trong quá trình huấn luyện. Đối với tập MNIST chúng ta dùng accuracy trên top1\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "             metrics=[\"accuracy\"])\n",
    "    \n",
    "\n",
    "## In toàn bộ cấu trúc của model\n",
    "print(\"Cấu trúc của model: \")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31671a60cee805c34c73116577b485118ff3a75c458d3004d49632c19702ac60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
